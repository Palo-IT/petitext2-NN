{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATE QUESTION AND CALL R-NET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program enables to create question as of a text with NER. \n",
    "\n",
    "Then, the input (texts and questions) are sent to R-NET in order to have the answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of questions with Standford Core NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Launch the server</b>\n",
    "\n",
    "Installation : /home/ubuntu/spacework/spacework/StandfordCoreNLP/stanford-corenlp-full-2018-02-27</b>\n",
    "\n",
    "java -mx10g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corenlp\n",
    "\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "import os\n",
    "import numpy as np\n",
    "import ujson as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_question(text):\n",
    "    with corenlp.CoreNLPClient() as client:\n",
    "        #ann = client.annotate(text)\n",
    "        #print('annotations:\\n',ann)\n",
    "        \n",
    "        questions = []\n",
    "        \n",
    "        pattern_ner = '([ner: PERSON])'\n",
    "        matches_ner = client.tokensregex(text, pattern_ner)\n",
    "        print('matches_ner:\\n', matches_ner)\n",
    "\n",
    "        print('the number of sentences:',len(matches_ner[\"sentences\"]))\n",
    "\n",
    "        for nb_sent in range(len(matches_ner[\"sentences\"])):\n",
    "\n",
    "            if matches_ner[\"sentences\"][nb_sent][\"length\"] == 0:\n",
    "                print('No NER in the sentence')\n",
    "            else:\n",
    "                print('there is a ner in the sentence')\n",
    "                ner_text = matches_ner[\"sentences\"][nb_sent][\"0\"][\"text\"]\n",
    "                print('text_ner:\\n',ner_text)\n",
    "\n",
    "                #The differents types of verb\n",
    "                pattern_pos_vb = '(?:[pos: VB]|[pos: VBD]|[pos: VBG]|[pos: VBN]|[pos: VBP]|[pos: VBZ])'\n",
    "                matches_pos_vb = client.tokensregex(text, pattern_pos_vb)\n",
    "                print('matches_pos_vb:\\n', matches_pos_vb)\n",
    "\n",
    "                if matches_pos_vb[\"sentences\"][nb_sent][\"length\"] == 0:\n",
    "                    print('No VB in the sentence')\n",
    "                else:\n",
    "                    print('there is a verb in the sentence')\n",
    "                    pos_vb_text = matches_pos_vb[\"sentences\"][nb_sent][\"0\"][\"text\"]\n",
    "                    print('pos_vb_text:\\n',pos_vb_text)\n",
    "\n",
    "                    question = 'Where %s %s?' % (pos_vb_text,ner_text) \n",
    "                    print('question : ', question)\n",
    "                    print('nb_sent : ', nb_sent)\n",
    "                    questions.append(question)\n",
    "        return questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"Gloria play in the park.\" \\\n",
    "          \" A passenger railway in an urban area with high capacity and frequency. \" \\\n",
    "          \" Arthur is in Brazil.\" \\\n",
    "          \" In meteorology, precipitation is any product of the condensation \" \\\n",
    "          \"of atmospheric water vapor that falls under gravity. The main forms \" \\\n",
    "          \"of precipitation include drizzle, rain, sleet, snow, graupel and hail.\" \\\n",
    "          \" Sonia is in the car.\" \\\n",
    "          \" Precipitation forms as smaller droplets coalesce via collision with other \" \\\n",
    "          \"rain drops or ice crystals within a cloud. Short, intense periods of rain \" \\\n",
    "          \"in scattered locations are called showers.\" \\\n",
    "          \" Adrien is in the salsa club.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gloria play in the park.\n",
      "A passenger railway in an urban area with high capacity and frequency.\n",
      " Arthur is in Brazil.\n",
      "In meteorology, precipitation is any product of the condensation of atmospheric water vapor that falls under gravity.\n",
      "The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail.\n",
      "Sonia is in the car.\n",
      "Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud.\n",
      "Short, intense periods of rain in scattered locations are called showers.\n",
      "Adrien is in the salsa club.\n",
      "matches_ner:\n",
      " {'sentences': [{'0': {'text': 'Gloria', 'begin': 0, 'end': 1, '1': {'text': 'Gloria', 'begin': 0, 'end': 1}}, 'length': 1}, {'length': 0}, {'0': {'text': 'Arthur', 'begin': 0, 'end': 1, '1': {'text': 'Arthur', 'begin': 0, 'end': 1}}, 'length': 1}, {'length': 0}, {'length': 0}, {'0': {'text': 'Sonia', 'begin': 0, 'end': 1, '1': {'text': 'Sonia', 'begin': 0, 'end': 1}}, 'length': 1}, {'length': 0}, {'length': 0}, {'0': {'text': 'Adrien', 'begin': 0, 'end': 1, '1': {'text': 'Adrien', 'begin': 0, 'end': 1}}, 'length': 1}]}\n",
      "the number of sentences: 9\n",
      "there is a ner in the sentence\n",
      "text_ner:\n",
      " Gloria\n",
      "matches_pos_vb:\n",
      " {'sentences': [{'0': {'text': 'play', 'begin': 1, 'end': 2}, 'length': 1}, {'length': 0}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}, {'0': {'text': 'is', 'begin': 4, 'end': 5}, '1': {'text': 'falls', 'begin': 15, 'end': 16}, 'length': 2}, {'0': {'text': 'include', 'begin': 5, 'end': 6}, 'length': 1}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}, {'0': {'text': 'coalesce', 'begin': 5, 'end': 6}, 'length': 1}, {'0': {'text': 'scattered', 'begin': 7, 'end': 8}, '1': {'text': 'are', 'begin': 9, 'end': 10}, '2': {'text': 'called', 'begin': 10, 'end': 11}, 'length': 3}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}]}\n",
      "there is a verb in the sentence\n",
      "pos_vb_text:\n",
      " play\n",
      "question :  Where play Gloria?\n",
      "nb_sent :  0\n",
      "No NER in the sentence\n",
      "there is a ner in the sentence\n",
      "text_ner:\n",
      " Arthur\n",
      "matches_pos_vb:\n",
      " {'sentences': [{'0': {'text': 'play', 'begin': 1, 'end': 2}, 'length': 1}, {'length': 0}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}, {'0': {'text': 'is', 'begin': 4, 'end': 5}, '1': {'text': 'falls', 'begin': 15, 'end': 16}, 'length': 2}, {'0': {'text': 'include', 'begin': 5, 'end': 6}, 'length': 1}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}, {'0': {'text': 'coalesce', 'begin': 5, 'end': 6}, 'length': 1}, {'0': {'text': 'scattered', 'begin': 7, 'end': 8}, '1': {'text': 'are', 'begin': 9, 'end': 10}, '2': {'text': 'called', 'begin': 10, 'end': 11}, 'length': 3}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}]}\n",
      "there is a verb in the sentence\n",
      "pos_vb_text:\n",
      " is\n",
      "question :  Where is Arthur?\n",
      "nb_sent :  2\n",
      "No NER in the sentence\n",
      "No NER in the sentence\n",
      "there is a ner in the sentence\n",
      "text_ner:\n",
      " Sonia\n",
      "matches_pos_vb:\n",
      " {'sentences': [{'0': {'text': 'play', 'begin': 1, 'end': 2}, 'length': 1}, {'length': 0}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}, {'0': {'text': 'is', 'begin': 4, 'end': 5}, '1': {'text': 'falls', 'begin': 15, 'end': 16}, 'length': 2}, {'0': {'text': 'include', 'begin': 5, 'end': 6}, 'length': 1}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}, {'0': {'text': 'coalesce', 'begin': 5, 'end': 6}, 'length': 1}, {'0': {'text': 'scattered', 'begin': 7, 'end': 8}, '1': {'text': 'are', 'begin': 9, 'end': 10}, '2': {'text': 'called', 'begin': 10, 'end': 11}, 'length': 3}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}]}\n",
      "there is a verb in the sentence\n",
      "pos_vb_text:\n",
      " is\n",
      "question :  Where is Sonia?\n",
      "nb_sent :  5\n",
      "No NER in the sentence\n",
      "No NER in the sentence\n",
      "there is a ner in the sentence\n",
      "text_ner:\n",
      " Adrien\n",
      "matches_pos_vb:\n",
      " {'sentences': [{'0': {'text': 'play', 'begin': 1, 'end': 2}, 'length': 1}, {'length': 0}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}, {'0': {'text': 'is', 'begin': 4, 'end': 5}, '1': {'text': 'falls', 'begin': 15, 'end': 16}, 'length': 2}, {'0': {'text': 'include', 'begin': 5, 'end': 6}, 'length': 1}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}, {'0': {'text': 'coalesce', 'begin': 5, 'end': 6}, 'length': 1}, {'0': {'text': 'scattered', 'begin': 7, 'end': 8}, '1': {'text': 'are', 'begin': 9, 'end': 10}, '2': {'text': 'called', 'begin': 10, 'end': 11}, 'length': 3}, {'0': {'text': 'is', 'begin': 1, 'end': 2}, 'length': 1}]}\n",
      "there is a verb in the sentence\n",
      "pos_vb_text:\n",
      " is\n",
      "question :  Where is Adrien?\n",
      "nb_sent :  8\n",
      "The questions are :\n",
      " ['Where play Gloria?', 'Where is Arthur?', 'Where is Sonia?', 'Where is Adrien?']\n"
     ]
    }
   ],
   "source": [
    "nlp_en= spacy.blank(\"en\")\n",
    "nlp_en.add_pipe(nlp_en.create_pipe('sentencizer'))\n",
    "doc_en = nlp_en(context)\n",
    "\n",
    "for sent in doc_en.sents:\n",
    "    print(sent)\n",
    "    \n",
    "questions = create_question(context)\n",
    "    \n",
    "print('The questions are :\\n', questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call R-NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func import cudnn_gru, native_gru, dot_attention, summ, ptr_net\n",
    "from prepro import word_tokenize, convert_idx\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# # Must be consistant with training\n",
    "char_limit = 16\n",
    "hidden = 75\n",
    "char_dim = 8\n",
    "char_hidden = 100\n",
    "use_cudnn = True\n",
    "\n",
    "# # File path\n",
    "target_dir = \"data\"\n",
    "save_dir = \"log_first_iteration_fasttext/model\"\n",
    "word_emb_file = os.path.join(target_dir, \"word_emb.json\")\n",
    "char_emb_file = os.path.join(target_dir, \"char_emb.json\")\n",
    "word2idx_file = os.path.join(target_dir, \"word2idx.json\")\n",
    "char2idx_file = os.path.join(target_dir, \"char2idx.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfModel(object):\n",
    "\n",
    "    def __init__(self, word_mat, char_mat):\n",
    "        self.c = tf.placeholder(tf.int32, [1, None])\n",
    "        self.q = tf.placeholder(tf.int32, [1, None])\n",
    "        self.ch = tf.placeholder(tf.int32, [1, None, char_limit])\n",
    "        self.qh = tf.placeholder(tf.int32, [1, None, char_limit])\n",
    "\n",
    "        self.word_mat = tf.get_variable(\"word_mat\", initializer=tf.constant(\n",
    "            word_mat, dtype=tf.float32), trainable=False)\n",
    "        self.char_mat = tf.get_variable(\n",
    "            \"char_mat\", initializer=tf.constant(char_mat, dtype=tf.float32))\n",
    "\n",
    "        self.c_mask = tf.cast(self.c, tf.bool)\n",
    "        self.q_mask = tf.cast(self.q, tf.bool)\n",
    "        self.c_len = tf.reduce_sum(tf.cast(self.c_mask, tf.int32), axis=1)\n",
    "        self.q_len = tf.reduce_sum(tf.cast(self.q_mask, tf.int32), axis=1)\n",
    "\n",
    "        self.c_maxlen = tf.reduce_max(self.c_len)\n",
    "        self.q_maxlen = tf.reduce_max(self.q_len)\n",
    "\n",
    "        self.ch_len = tf.reshape(tf.reduce_sum(\n",
    "            tf.cast(tf.cast(self.ch, tf.bool), tf.int32), axis=2), [-1])\n",
    "        self.qh_len = tf.reshape(tf.reduce_sum(\n",
    "            tf.cast(tf.cast(self.qh, tf.bool), tf.int32), axis=2), [-1])\n",
    "\n",
    "        self.ready()\n",
    "\n",
    "    def ready(self):\n",
    "        N, PL, QL, CL, d, dc, dg = 1, self.c_maxlen, self.q_maxlen, char_limit, hidden, char_dim, char_hidden\n",
    "        gru = cudnn_gru if use_cudnn else native_gru\n",
    "\n",
    "        with tf.variable_scope(\"emb\"):\n",
    "            with tf.variable_scope(\"char\"):\n",
    "                ch_emb = tf.reshape(tf.nn.embedding_lookup(\n",
    "                    self.char_mat, self.ch), [N * PL, CL, dc])\n",
    "                qh_emb = tf.reshape(tf.nn.embedding_lookup(\n",
    "                    self.char_mat, self.qh), [N * QL, CL, dc])\n",
    "                cell_fw = tf.contrib.rnn.GRUCell(dg)\n",
    "                cell_bw = tf.contrib.rnn.GRUCell(dg)\n",
    "                _, (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                    cell_fw, cell_bw, ch_emb, self.ch_len, dtype=tf.float32)\n",
    "                ch_emb = tf.concat([state_fw, state_bw], axis=1)\n",
    "                _, (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                    cell_fw, cell_bw, qh_emb, self.qh_len, dtype=tf.float32)\n",
    "                qh_emb = tf.concat([state_fw, state_bw], axis=1)\n",
    "                qh_emb = tf.reshape(qh_emb, [N, QL, 2 * dg])\n",
    "                ch_emb = tf.reshape(ch_emb, [N, PL, 2 * dg])\n",
    "\n",
    "            with tf.name_scope(\"word\"):\n",
    "                c_emb = tf.nn.embedding_lookup(self.word_mat, self.c)\n",
    "                q_emb = tf.nn.embedding_lookup(self.word_mat, self.q)\n",
    "\n",
    "            c_emb = tf.concat([c_emb, ch_emb], axis=2)\n",
    "            q_emb = tf.concat([q_emb, qh_emb], axis=2)\n",
    "\n",
    "        with tf.variable_scope(\"encoding\"):\n",
    "            rnn = gru(num_layers=3, num_units=d, batch_size=N,\n",
    "                      input_size=c_emb.get_shape().as_list()[-1])\n",
    "            c = rnn(c_emb, seq_len=self.c_len)\n",
    "            q = rnn(q_emb, seq_len=self.q_len)\n",
    "\n",
    "        with tf.variable_scope(\"attention\"):\n",
    "            qc_att = dot_attention(c, q, mask=self.q_mask, hidden=d)\n",
    "            rnn = gru(num_layers=1, num_units=d, batch_size=N,\n",
    "                      input_size=qc_att.get_shape().as_list()[-1])\n",
    "            att = rnn(qc_att, seq_len=self.c_len)\n",
    "\n",
    "        with tf.variable_scope(\"match\"):\n",
    "            self_att = dot_attention(att, att, mask=self.c_mask, hidden=d)\n",
    "            rnn = gru(num_layers=1, num_units=d, batch_size=N,\n",
    "                      input_size=self_att.get_shape().as_list()[-1])\n",
    "            match = rnn(self_att, seq_len=self.c_len)\n",
    "\n",
    "        with tf.variable_scope(\"pointer\"):\n",
    "            init = summ(q[:, :, -2 * d:], d, mask=self.q_mask)\n",
    "            pointer = ptr_net(batch=N, hidden=init.get_shape().as_list()[-1])\n",
    "            logits1, logits2 = pointer(init, match, d, self.c_mask)\n",
    "\n",
    "        with tf.variable_scope(\"predict\"):\n",
    "            outer = tf.matmul(tf.expand_dims(tf.nn.softmax(logits1), axis=2),\n",
    "                              tf.expand_dims(tf.nn.softmax(logits2), axis=1))\n",
    "            outer = tf.matrix_band_part(outer, 0, 15)\n",
    "            self.yp1 = tf.argmax(tf.reduce_max(outer, axis=2), axis=1)\n",
    "            self.yp2 = tf.argmax(tf.reduce_max(outer, axis=1), axis=1)\n",
    "\n",
    "\n",
    "class Inference(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        with open(word_emb_file, \"r\") as fh:\n",
    "            self.word_mat = np.array(json.load(fh), dtype=np.float32)\n",
    "        with open(char_emb_file, \"r\") as fh:\n",
    "            self.char_mat = np.array(json.load(fh), dtype=np.float32)\n",
    "        with open(word2idx_file, \"r\") as fh:\n",
    "            self.word2idx_dict = json.load(fh)\n",
    "        with open(char2idx_file, \"r\") as fh:\n",
    "            self.char2idx_dict = json.load(fh)\n",
    "        self.model = InfModel(self.word_mat, self.char_mat)\n",
    "        sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "        sess_config.gpu_options.allow_growth = True\n",
    "        self.sess = tf.Session(config=sess_config)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(self.sess, tf.train.latest_checkpoint(save_dir))\n",
    "\n",
    "    def response(self, context, question):\n",
    "        sess = self.sess\n",
    "        model = self.model\n",
    "        span, context_idxs, ques_idxs, context_char_idxs, ques_char_idxs = self.prepro(\n",
    "            context, question)\n",
    "        yp1, yp2 = sess.run([model.yp1, model.yp2], feed_dict={\n",
    "                            model.c: context_idxs, model.q: ques_idxs, model.ch: context_char_idxs, model.qh: ques_char_idxs})\n",
    "        start_idx = span[yp1[0]][0]\n",
    "        end_idx = span[yp2[0]][1]\n",
    "        return context[start_idx: end_idx]\n",
    "\n",
    "    def prepro(self, context, question):\n",
    "        context = context.replace(\"''\", '\" ').replace(\"``\", '\" ')\n",
    "        context_tokens = word_tokenize(context)\n",
    "        context_chars = [list(token) for token in context_tokens]\n",
    "        spans = convert_idx(context, context_tokens)\n",
    "        ques = question.replace(\"''\", '\" ').replace(\"``\", '\" ')\n",
    "        ques_tokens = word_tokenize(ques)\n",
    "        ques_chars = [list(token) for token in ques_tokens]\n",
    "\n",
    "        context_idxs = np.zeros([1, len(context_tokens)], dtype=np.int32)\n",
    "        context_char_idxs = np.zeros(\n",
    "            [1, len(context_tokens), char_limit], dtype=np.int32)\n",
    "        ques_idxs = np.zeros([1, len(ques_tokens)], dtype=np.int32)\n",
    "        ques_char_idxs = np.zeros(\n",
    "            [1, len(ques_tokens), char_limit], dtype=np.int32)\n",
    "\n",
    "        def _get_word(word):\n",
    "            for each in (word, word.lower(), word.capitalize(), word.upper()):\n",
    "                if each in self.word2idx_dict:\n",
    "                    return self.word2idx_dict[each]\n",
    "            return 1\n",
    "\n",
    "        def _get_char(char):\n",
    "            if char in self.char2idx_dict:\n",
    "                return self.char2idx_dict[char]\n",
    "            return 1\n",
    "\n",
    "        for i, token in enumerate(context_tokens):\n",
    "            context_idxs[0, i] = _get_word(token)\n",
    "\n",
    "        for i, token in enumerate(ques_tokens):\n",
    "            ques_idxs[0, i] = _get_word(token)\n",
    "\n",
    "        for i, token in enumerate(context_chars):\n",
    "            for j, char in enumerate(token):\n",
    "                if j == char_limit:\n",
    "                    break\n",
    "                context_char_idxs[0, i, j] = _get_char(char)\n",
    "\n",
    "        for i, token in enumerate(ques_chars):\n",
    "            for j, char in enumerate(token):\n",
    "                if j == char_limit:\n",
    "                    break\n",
    "                ques_char_idxs[0, i, j] = _get_char(char)\n",
    "        return spans, context_idxs, ques_idxs, context_char_idxs, ques_char_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from log_first_iteration_fasttext/model/model_60000.ckpt\n"
     ]
    }
   ],
   "source": [
    "infer = Inference()\n",
    "\n",
    "# infer = Inference()\n",
    "# context = \"In meteorology, precipitation is any product of the condensation \" \\\n",
    "#           \"of atmospheric water vapor that falls under gravity. The main forms \" \\\n",
    "#           \"of precipitation include drizzle, rain, sleet, snow, graupel and hail.\" \\\n",
    "#           \"Precipitation forms as smaller droplets coalesce via collision with other \" \\\n",
    "#           \"rain drops or ice crystals within a cloud. Short, intense periods of rain \" \\\n",
    "#           \"in scattered locations are called “showers”.\"\n",
    "# ques1 = \"What causes precipitation to fall?\"\n",
    "# ques2 = \"What is another main form of precipitation besides drizzle, rain, snow, sleet and hail?\"\n",
    "# ques3 = \"Where do water droplets collide with ice crystals to form precipitation?\"\n",
    "\n",
    "# # Correct: gravity, Output: drizzle, rain, sleet, snow, graupel and hail\n",
    "# ans1 = infer.response(context, ques1)\n",
    "# print(\"Answer 1: {}\".format(ans1))\n",
    "\n",
    "# # Correct: graupel, Output: graupel\n",
    "# ans2 = infer.response(context, ques2)\n",
    "# print(\"Answer 2: {}\".format(ans2))\n",
    "\n",
    "# # Correct: within a cloud, Output: within a cloud\n",
    "# ans3 = infer.response(context, ques3)\n",
    "# print(\"Answer 3: {}\".format(ans3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions: \n",
      " ['Where play Gloria?', 'Where is Arthur?', 'Where is Sonia?', 'Where is Adrien?']\n",
      "Question : Where play Gloria? the park\n",
      "Question : Where is Arthur? Brazil\n",
      "Question : Where is Sonia? the car\n",
      "Question : Where is Adrien? the salsa club\n"
     ]
    }
   ],
   "source": [
    "print('questions: \\n', questions)\n",
    "\n",
    "for question in questions:\n",
    "    ans = infer.response(context, question)\n",
    "    \n",
    "    print(\"Question : {} - Answer : {}\".format(question, ans))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
